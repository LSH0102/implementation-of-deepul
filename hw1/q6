import pickle
import copy
import math
from transformer import ABS_RoPE,Embedding,Transformer_Block
from einops import einsum,rearrange
import numpy as np
import torch 
from torch import nn
from deepul.hw1_helper import (
    # Q1
    visualize_q1_data,
    q1_sample_data_1,
    q1_sample_data_2,
    q1_save_results,
    # Q2
    q2a_save_results,
    q2b_save_results,
    visualize_q2a_data,
    visualize_q2b_data,
    # Q3
    q3ab_save_results,
    q3c_save_results,
    # Q4
    q4a_save_results,
    q4b_save_results,
    # Q5
    visualize_q5_data,
    q5a_save_results,
    # Q6
    visualize_q6_data,
    q6a_save_results,
)

device='cuda'

def tokenize_text(text):
    total=len(text)
    x=[]
    d1=dict()
    d2=dict()
    d1['<bos>']=0
    d2[0]='<bos>'
    v=1
    d1['<eos>']=1
    d2[1]='<eos>'
    v=2
    for i in range(0,total):
        t=text[i]
        t=t.split(' ')
        seq=[0]
        for item in t:
            if item not in d1:
                d1[item]=v
                d2[v]=item
                seq.append(v)
                v+=1
            else:
                seq.append(d1[item])
        seq.append(1)
        
        x.append(seq)
    x=np.array(x)
    
    with open('word2num','wb') as f:
        pickle.dump(d1, f)
    with open('num2word','wb') as f:
        pickle.dump(d2, f)
    np.save('text_tokens.npy',x)
def decode_text(num2word:dict, text):
    x=""
    for i in range(1,text.shape[0]-1):
       if i==0:
           x+=num2word[text[i]]
       else:
           x+=" "+num2word[text[i]]
    return x

def encode_image(image,vqvae):
    n_embedding=vqvae.n_embeddings
    vqvae.to(device)
    encoded_image=vqvae.quantize(image[:10000])
    H=encoded_image.shape[1]
    W=encoded_image.shape[2]
    encoded_image=encoded_image.reshape((10000,H*W)).to('cpu')
    h1=n_embedding*np.ones((10000,1))
    h2=(n_embedding+1)*np.ones((10000,1))
    h=np.concatenate((h1, encoded_image,h2),axis=1)
    np.save('image_tokens_test.npy',h)

def test_batch(vqvae):
    with open('word2num','rb') as f:
        word2num=pickle.load(f)
    with open('num2word','rb') as f:
        num2word=pickle.load(f)
    text_tokens=np.load('text_tokens.npy')
    
    h=np.load('image_tokens.npy')
    
    rand1=np.random.randint(0,60000,size=(9,))
    rand2=np.random.randint(0,60000,size=(9,))
    rand3=np.random.randint(0,60000,size=(9,))
    
    sample1=[]
    sample2=[]
    sample3=[]
    texts1=text_tokens[rand1]
    texts2=text_tokens[rand2]
    texts3=text_tokens[rand3]
    
    image1=h[rand1][:,1:-1].reshape((texts1.shape[0],7,7))
    image2=h[rand2][:,1:-1].reshape((texts2.shape[0],7,7))
    image3=h[rand3][:,1:-1].reshape((texts3.shape[0],7,7))
    image1=vqvae.decode(image1)
    image2=vqvae.decode(image2)
    image3=vqvae.decode(image3)
    
    sample1=[(image1[i],decode_text(num2word, texts1[i][1:-1])) for i in range(0,image1.shape[0])]
    sample2=[(image2[i],decode_text(num2word, texts2[i][1:-1])) for i in range(0,image2.shape[0])]
    sample3=[(image3[i],decode_text(num2word, texts3[i][1:-1])) for i in range(0,image3.shape[0])]


def _get_clones(module, N):
    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])


class iGPT(nn.Module):
    def __init__(self,d_model,vocab_size, H,W,context_length,num_layers,num_heads,
                 d_ff,theta,max_seq_len,start_of_token,end_of_token):
        super().__init__()
        
        self.H=H
        self.W=W
        
        if max_seq_len==None:
            max_seq_len=context_length

        self.pe=ABS_RoPE(theta, d_model, max_seq_len).to(device)
        self.embedding=Embedding(vocab_size, d_model).to(device)
        
        Layer=Transformer_Block(d_model, num_heads, d_ff).to(device)
        
        self.Trans=_get_clones(Layer,num_layers)

        self.Linear=torch.nn.Linear(d_model, vocab_size)
        
        self.lm=torch.nn.LayerNorm(vocab_size).to(device)
        self.layers=num_layers
        self.d_model=d_model
        
        self.vocab_size=vocab_size
        
        self.softmax=torch.nn.Softmax(dim=-1)
    
        self.bos=start_of_token
        self.eos=end_of_token
    
    def forward(self,x:np.ndarray):
        
        x=torch.LongTensor(x).to(device)
        x=x.to(device)
        x=self.embedding(x)
        x=self.pe(x)
        for i in range(0,self.layers):
            x=self.Trans[i](x)
    
        x=self.Linear(x)
        x=self.lm(x)
        x=self.softmax(x)
        
        return x
    
    def compute_maxlikelihood(self,x:np.ndarray):
        prob=self.forward(x[:,:-1]).to(device)
        
        y=torch.LongTensor(x[:,1:]).to(dtype=torch.int64).to(device)
        y=y.unsqueeze(-1)
        p=torch.gather(prob, dim=-1, index=y).squeeze()
        L=torch.log(p)
        return L.mean()
    
    def sample(self,num_samples):
        with torch.no_grad():
            h=(self.vocab_size-1)*np.ones(shape=(num_samples,1))
            
            for i in range(0,self.H):
                for j in range(0,self.W):
                    probs=self.forward(h)
                    
                    dist=torch.distributions.Categorical(probs=probs)
                    next_pixcel=dist.sample().cpu().detach().numpy()[:,[-1]]
                    h=np.concatenate((h, next_pixcel),axis=1)
                    
            sample=h[:,1:]
            
            sample=sample.reshape((num_samples,self.W,self.H))
        return sample
    
    def sample_texts_give_imgs(self,image):
        h=image.reshape((1,51))#变成(1,51)的图片
        for i in range(0,100): #强制限制最多生成100词
            probs=self.forward(h)
            dist=torch.distributions.Categorical(probs=probs)
            next_pixcel=dist.sample().cpu().detach().numpy()[:,[-1]]
            h=np.concatenate((h, next_pixcel),axis=1)
            
            #如果生成了'<eos>' 那么循环结束
            
            if h[0,-1]==self.eos:
                break
        
        return h
    
    def sample_images_give_texts(self,text):
        text_len=text.shape[-1]
        h=text.reshape((1,text_len))
        boi=np.zeros((1,1))
        #添加 <begin of image>
        h=np.concatenate((h, boi,),axis=1)
        for i in range(0,50): #连带 <boi>总共51个token, 加入<boi>之后只需预测后面50个
            probs=self.forward(h)
            dist=torch.distributions.Categorical(probs=probs)
            next_pixcel=dist.sample().cpu().detach().numpy()[:,[-1]]
            h=np.concatenate((h, next_pixcel),axis=1)
        return h
        
        
        

def q6_a(train_data, test_data, image_shape, train_text, test_text, image_test_prompt, text_test_prompt, vqvae):
    
    #tokenize_text(train_text)  
    #encode_image(train_data, vqvae)
    with open('word2num','rb') as f:
        word2num=pickle.load(f)
    with open('num2word','rb') as f:
        num2word=pickle.load(f)
    text_tokens=np.load('text_tokens.npy')
    
    
    test_tokens=np.load('text_tokens_test.npy')
    
    
    text_token_bias=vqvae.n_embeddings+2
    text_tokens+=text_token_bias      #为了保证text的token和image的token互不相同 给所有text_token加上image_token的总数(49+2=51)
    test_tokens+=text_token_bias      #对test数据进行同样的处理
    
    h=np.load('image_tokens.npy')
    
    h1=np.load('image_tokens_test.npy')
    
    total=h.shape[0]
    batch_size=100
    n_batches=total//batch_size
    
    vocab_size=vqvae.n_embeddings+2+len(num2word) #总的词汇量长度应该是img的token总数+text的token总数
    context_length=h.shape[1]+text_tokens.shape[1]
    H=7
    W=7
    d_model=256
    model=iGPT(d_model, vocab_size, H, W, context_length, num_layers=4, num_heads=8, d_ff=128, theta=10000,
               max_seq_len=context_length,start_of_token=text_token_bias,end_of_token=word2num['<eos>']+text_token_bias)
    model.to(device)
    
    model.load_state_dict(torch.load('iGPT_q6.pth'))
    
    opt=torch.optim.Adam(model.parameters(),lr=1e-3)
    
    epoch=0
    train_losses=[]
    
    for i in range(0,epoch):
        rand_indices = np.random.randint(0,total, size=(batch_size*n_batches,))
        for j in range(0,n_batches):
            text_data1=text_tokens[rand_indices[j*batch_size:j*batch_size+batch_size//2]]
            text_data2=text_tokens[rand_indices[j*batch_size+batch_size//2:(j+1)*batch_size]]
            
            img_data1=h[rand_indices[j*batch_size:j*batch_size+batch_size//2]]
            img_data2=h[rand_indices[j*batch_size+batch_size//2:(j+1)*batch_size]]
        
            
            data1=np.concatenate( (text_data1, img_data1),axis=1)
            data2=np.concatenate((img_data2,text_data2),axis=1)
            data=np.concatenate( (data1, data2),axis=0)
            
            L=-model.compute_maxlikelihood(data)
            print(i,L.item())
            opt.zero_grad()
            L.backward()
            opt.step()
            
            train_losses.append(L.item())
            
        torch.save(model.state_dict(),'iGPT_q6.pth')
    
    train_losses=np.array(train_losses)
    
    rand1=np.random.randint(0,10000,size=(9,))
    rand2=np.random.randint(0,10000,size=(9,))
    
    imgs=h1[rand1] #(9,51)的数组
    img=imgs[:,1:-1].reshape((9,7,7))
    img=vqvae.decode(img)
    samples=[(img[i],model.sample_texts_give_imgs(imgs[i])[0][51:]) for i in range(0,9)]
    sample1=[(img[i],decode_text(num2word, samples[i][1]-text_token_bias)) for i in range(0,9)]
    
    sample_text=test_tokens[rand2] #不要忘记还没有减去text_token_bias
    samples=[(model.sample_images_give_texts(sample_text[i]),decode_text(num2word, sample_text[i]-text_token_bias)) for i in range(0,9)]
    #对img tokens clip一下 要不然vae无法把超出img_embedding范围的token转换成像素
    samples=[(samples[i][0][0].clip(0,vqvae.n_embeddings-1),samples[i][1]) for i in range(0,9)]
    samples=[(samples[i][0][-50:-1].reshape((1,7,7)),samples[i][1]) for i in range(0,9)]
    
    sample2=[(vqvae.decode(samples[i][0])[0],samples[i][1]) for i in range(0,9)]
    
    return train_losses,[1],sample1,sample2,sample2

q6a_save_results(q6_a)
