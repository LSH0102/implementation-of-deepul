import copy
import torch
import torch.nn as nn
from torch.optim.lr_scheduler import LambdaLR
from transformer import ABS_RoPE,Embedding,Transformer_Block
from deepul.hw3_utils.lpips import LPIPS
from deepul.hw3_helper import *
import deepul.pytorch_util as ptu
import warnings
warnings.filterwarnings('ignore')
device='cuda'

def _get_clones(module, N):
    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])


class iGPT(nn.Module):
    def __init__(self,d_model,vocab_size, H,W,context_length,num_layers,num_heads,d_ff,theta,max_seq_len):
        super().__init__()
        
        self.H=H
        self.W=W
        
        if max_seq_len==None:
            max_seq_len=context_length

        self.pe=ABS_RoPE(theta, d_model, max_seq_len).to(device)
        self.embedding=Embedding(vocab_size, d_model).to(device)
        
        Layer=Transformer_Block(d_model, num_heads, d_ff).to(device)
        
        self.Trans=_get_clones(Layer,num_layers)

        self.Linear=torch.nn.Linear(d_model, vocab_size-1)
        
        self.lm=torch.nn.LayerNorm(vocab_size-1).to(device)
        self.layers=num_layers
        self.d_model=d_model
        
        self.vocab_size=vocab_size
        
        self.softmax=torch.nn.Softmax(dim=-1)
    
    
    def forward(self,x:np.ndarray):
        
        x=torch.LongTensor(x).to(device)
        x=x.to(device)
        x=self.embedding(x)
        x=self.pe(x)
        for i in range(0,self.layers):
            x=self.Trans[i](x)
    
        x=self.Linear(x)
        x=self.lm(x)
        x=self.softmax(x)
        
        return x
    
    def compute_maxlikelihood(self,x:np.ndarray):
        prob=self.forward(x[:,:-1]).to(device)
        
        y=torch.LongTensor(x[:,1:]).to(dtype=torch.int64).to(device)
        y=y.unsqueeze(-1)
        p=torch.gather(prob, dim=-1, index=y).squeeze()
        L=torch.log(p)
        return L.mean()
    
    def sample(self,num_samples):
        with torch.no_grad():
            h=(self.vocab_size-1)*np.ones(shape=(num_samples,1))
            
            for i in range(0,self.H):
                for j in range(0,self.W):
                    probs=self.forward(h)
                    
                    dist=torch.distributions.Categorical(probs=probs)
                    next_pixcel=dist.sample().cpu().detach().numpy()[:,[-1]]
                    h=np.concatenate((h, next_pixcel),axis=1)
                    
            sample=h[:,1:]
            
            sample=sample.reshape((num_samples,self.H,self.W))
        return sample
    
class residual_block(nn.Module):
    def __init__(self,dim:int):
        super().__init__()
        self.bn1=torch.nn.BatchNorm2d(dim)
        self.acti=torch.nn.ReLU()
        self.conv1=torch.nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3,stride=1,padding=1)
        self.bn2=torch.nn.BatchNorm2d(dim)
        self.conv2=torch.nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3,stride=1,padding=1)
        
    def forward(self,x:torch.Tensor):
        x=self.bn1(x)
        x=self.acti(x)
        x=self.conv1(x)
        x=self.bn2(x)
        x=self.acti(x)
        x=self.conv2(x)
        return x
    
class Encoder(nn.Module):
    def __init__(self,dim:int):
        super().__init__()
        self.conv1=torch.nn.Conv2d(in_channels=3, out_channels=dim, kernel_size=4,stride=2,padding=1)
        self.bn1=torch.nn.BatchNorm2d(dim)
        self.acti=torch.nn.ReLU()
        self.conv2=torch.nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=4,stride=2,padding=1)
        self.rs1=residual_block(dim)
        self.rs2=residual_block(dim)
        
    def forward(self,x:torch.Tensor):
        x=self.conv1(x)
        x=self.bn1(x)
        x=self.acti(x)
        x=self.conv2(x)
        x=self.rs1(x)
        x=self.rs2(x)
        return x
    
class Decoder(nn.Module):
    def __init__(self,dim:int):
        super().__init__()
        self.rs1=residual_block(dim)
        self.rs2=residual_block(dim)
        self.bn1=torch.nn.BatchNorm2d(dim)
        self.acti=torch.nn.ReLU()
        self.conv1=torch.nn.ConvTranspose2d(in_channels=dim, out_channels=dim, kernel_size=4,stride=2,padding=1)
        self.bn2=torch.nn.BatchNorm2d(dim)
        self.conv2=torch.nn.ConvTranspose2d(in_channels=dim, out_channels=3, kernel_size=4,stride=2,padding=1)

    def forward(self,x:torch.Tensor):
        x=self.rs1(x)
        x=self.rs2(x)
        x=self.bn1(x)
        x=self.acti(x)
        x=self.conv1(x)
        x=self.bn2(x)
        x=self.acti(x)
        x=self.conv2(x)
        return x
    
class VQVAE(nn.Module):
    def __init__(self,dim:int,H,W,K,D,beta=0.2,gamma=0.99):
        super().__init__()
        self.dim=dim
        self.H=H
        self.W=W
        self.K=K
        self.D=D
        t=torch.empty((K,D),device=device)
        self.codebook=torch.nn.init.uniform_(t,-1,1)
        self.encoder=Encoder(self.dim).to(device)
        self.decoder=Decoder(self.dim).to(device)
        
        self.recon_fn=torch.nn.MSELoss()
        self.beta=beta
        self.gamma=0.99
        self.N=torch.zeros((K,),device=device)
        self.m=torch.zeros((self.K,self.D),device=device)
        self.prior=iGPT(d_model=128, vocab_size=self.K+1, H=self.H, W=self.W, 
                        context_length=self.H*self.W, num_layers=4, num_heads=4, d_ff=128, theta=10000, max_seq_len=self.H*self.W)
    def compute_ek(self,x:np.ndarray):
        x=torch.Tensor(x).to(device)
        Ex=self.encoder(x)
        batch_size=x.shape[0]
        Ex=Ex.reshape((batch_size,self.dim,self.H*self.W)).permute(0,2,1)  #(batch_size,64,256)
        Ex=Ex.reshape((batch_size*64,self.dim))
        
        dist=torch.cdist(Ex,self.codebook)
        indices=torch.argmin(dist,dim=-1)   #抽出和每个z最近的索引
        
        
        return Ex,indices
        
    def VAE_LOSS(self,x:np.ndarray):
        batch_size=x.shape[0]
        Ze,indices=self.compute_ek(x)
        indices=indices.unsqueeze(1)
        prior_data=indices.reshape((batch_size,64)).cpu().detach().numpy()
        ind2=indices
        indices=indices.broadcast_to((indices.shape[0],256)).to(torch.int64)
        Zq=torch.gather(self.codebook,dim=0,index=indices)
        
        feature=(Zq-Ze).detach()+Ze
        feature=feature.reshape((batch_size,64,256))
        feature=feature.permute(0,2,1)
        feature=feature.reshape((batch_size,256,self.H,self.W))
        
        Dx=self.decoder(feature)
        x=torch.Tensor(x).to(device)
        recon_loss=self.recon_fn(Dx,x)
        
        Ze=Ze.reshape((batch_size,64,256))
        ek=Zq.reshape((batch_size,64,256))
        sgZe=Ze.detach()
        VQ=self.recon_fn(sgZe,ek)
        
        sgek=ek.detach()
        comm_loss=self.recon_fn(Ze,sgek)
        
        
        #然后更新e_k
        with torch.no_grad():
            ind=torch.zeros((indices.shape[0],self.codebook.shape[0]),device=device)
            ind=ind.scatter(1, ind2, 1)
            
            self.N=self.gamma*self.N+(1-self.gamma)*ind.sum(dim=0)
            self.m=self.gamma*self.m+(1-self.gamma)*torch.matmul(ind.T,Ze.reshape((batch_size*64,256)))
            deno=self.N.sum()
            self.N=(self.N+1e-5)*deno/(deno+self.K*1e-5)
            self.codebook=self.m/self.N.unsqueeze(1)
        return recon_loss+VQ+self.beta*comm_loss,prior_data, Dx
    
    def recon(self,x:np.ndarray):
        with torch.no_grad():
            batch_size=x.shape[0]
            Ze,indices=self.compute_ek(x)
            x=torch.Tensor(x).to(device)
            
            indices=indices.unsqueeze(1)
            indices=indices.broadcast_to((indices.shape[0],256)).to(torch.int64)
            Zq=torch.gather(self.codebook,dim=0,index=indices)
            
            feature=Zq
            feature=feature.reshape((batch_size,64,256))
            feature=feature.permute(0,2,1)
            feature=feature.reshape((batch_size,256,self.H,self.W))
            
            Dx=self.decoder(feature)
        return Dx.cpu().detach().numpy()
    
    def sample(self,num_samples):
        sample=self.prior.sample(num_samples)  #采样出(100,8,8)个token
        sample=sample.reshape((6400,1))
        sample=torch.LongTensor(sample).to(device)
        sample=sample.broadcast_to((6400,self.D))
        zq=torch.gather(self.codebook,dim=0,index=sample)
        zq=zq.reshape((100,64,256)).permute((0,2,1))
        zq=zq.reshape((100,256,8,8))
        x=(self.decoder(zq)+1.0)*255.0/2.0
        return x.cpu().detach().numpy()
    
class Space2Depth(nn.Module):
    def __init__(self,block_size:int):
        super().__init__()
        self.block_size=block_size
        self.block_size_sq=block_size*block_size
    def forward(self,x:torch.Tensor):
        out=x.permute(0,2,3,1)
        batch_size,s_height,s_width,s_depth=out.shape
        d_depth=s_depth*self.block_size_sq
        d_width=int(s_width/self.block_size)
        d_height=int(s_height/self.block_size)
        t_1=out.split(self.block_size,2)
        stack=[ t_t.reshape((batch_size,d_height,d_depth)) for t_t in t_1]
        out=torch.stack(stack,1)
        out=out.permute(0,2,1,3)
        out=out.permute(0,3,1,2)
        return out
class Downsample_Conv2d(nn.Module):
    def __init__(self,in_dim,out_dim,kernel_size=(3,3),stride=1,padding=1):
        super().__init__()
        self.Sp2Dep=Space2Depth(block_size=2)
        self.conv=torch.nn.Conv2d(in_channels=in_dim, out_channels=out_dim, kernel_size=kernel_size,stride=stride,padding=padding)
    def forward(self,x:torch.Tensor):
        x=self.Sp2Dep(x)
        x1,x2,x3,x4=x.chunk(4,dim=1)
        x=(x1+x2+x3+x4)/4.0
        x=self.conv(x)
        return x
class ResnetBlockDown(nn.Module):
    def __init__(self,in_dim:int, kernel_size=(3,3), n_filters=256):
        super().__init__()
        self.acti=torch.nn.ReLU()
        self.conv=torch.nn.Conv2d(in_channels=in_dim, out_channels=n_filters, kernel_size=kernel_size,padding=1).to(device)
        self.D1=Downsample_Conv2d(n_filters, n_filters,kernel_size,padding=1).to(device)
        self.D2=Downsample_Conv2d(in_dim, n_filters,kernel_size=(1,1),padding=0).to(device)
    def forward(self,x:torch.Tensor):
        y=x
        y=self.conv(y)
        y=self.acti(y)
        residual=self.D1(y)
        shortcut=self.D2(x)
        return residual+shortcut
class ResBlock(nn.Module):
    def __init__(self,n_filters=128):
        super().__init__()
        self.conv1=nn.Conv2d(in_channels=n_filters, out_channels=n_filters, kernel_size=(3,3),padding=1).to(device)
        self.acti=nn.ReLU()
        self.conv2=nn.Conv2d(in_channels=n_filters, out_channels=n_filters, kernel_size=(3,3),padding=1).to(device)
    def forward(self,x:torch.Tensor):
        x=self.acti(x)
        x=self.conv1(x)
        x=self.acti(x)
        x=self.conv2(x)
        return x

class Discriminator(nn.Module):
    def __init__(self,n_filters=128):
        super().__init__()
        self.RD1=ResnetBlockDown(3,n_filters=n_filters).to(device)
        self.RD2=ResnetBlockDown(128,n_filters=n_filters).to(device)
        self.Rs1=ResBlock(n_filters)
        self.Rs2=ResBlock(n_filters)
        self.acti=nn.ReLU()
        self.L=nn.Linear(n_filters, 1)
        self.sig=torch.nn.Sigmoid()
        
    def forward(self,x:torch.Tensor):
        x=(x+1.0)/2.0
        e=[]
        o=[]
        y=x.split(8,dim=2)
        for y1 in y:
            for item in y1.split(8,dim=-1):
                e.append(item)
        
        for item in e:
            x=item
            x=self.RD1(x)
            x=self.RD2(x)
            x=self.Rs1(x)
            x=self.Rs2(x)
            x=self.acti(x)
            x=torch.sum(x,dim=[-1,-2])
            x=self.L(x)
            o.append(x)
        o=torch.concat(o,dim=-1)
        o=0.03+0.95*self.sig(o)
        o=o.mean(dim=-1)
        return o

class VQGAN(nn.Module):
    def __init__(self,n_filters=128):
        super().__init__()
        self.VQVAE=VQVAE(dim=256, H=8, W=8, K=1024, D=256).to(device)
        self.D=Discriminator().to(device)
        
    def compute_loss(self,x:np.ndarray):
        Lvae,TF_prior,recon=self.VQVAE.VAE_LOSS(x)
        x=torch.Tensor(x).to(device)
        
        Ldis=torch.log(self.D(x))+torch.log(1-self.D(recon))
        Ldis=Ldis.mean()
        Lgen=-torch.log(self.D(recon))
        Lgen=Lgen.mean()
        
        Loss=LPIPS().to(device)
        Lper=Loss(x,recon).mean()
        
        return Lvae,Ldis,Lgen,Lper, TF_prior
        


def q3a(train_data, val_data, reconstruct_data):
    total=train_data.shape[0]
    batch_size=256
    
    n_batches=total//batch_size
    
    model=VQGAN()
    model.to(device)
    
    model.load_state_dict(torch.load('q3a.pth'))
    
    opt1=torch.optim.Adam(model.VQVAE.parameters(),lr=1e-3,betas=(0.5,0.9),weight_decay=0)
    opt2=torch.optim.Adam(model.VQVAE.prior.parameters(),lr=1e-3,betas=(0.5,0.9),weight_decay=0)
    opt3=torch.optim.Adam(model.D.parameters(),lr=1e-3,betas=(0.5,0.9),weight_decay=0)
    
    epoch=1
    dis_loss=[]
    per_loss=[]
    recon_train=[]
    recon_test=[]
    for i in range(0,epoch):
        rand=np.random.randint(0,total,size=(batch_size*n_batches,))
        for j in range(0,n_batches):
            data=train_data[rand[j*batch_size:(j+1)*batch_size]]
            data=2.0*(data-data.min())/(data.max()-data.min())-1.0
            Lvae,Ldis,Lgen,Lper,prior_data=model.compute_loss(data)
            
            dis_loss.append(Ldis.item())
            per_loss.append(Lper.item())
            recon_train.append(Lvae.item())
            L=-Ldis
            opt3.zero_grad()
            L.backward()
            opt3.step()
            print(i,Lvae.item(),Ldis.item(),Lper.item())
            
            Lvae,Ldis,Lgen,Lper,prior_data=model.compute_loss(data)
            opt1.zero_grad()
            L=Lvae+0.5*Lper+0.1*Lgen
            L.backward()
            opt1.step()
            #h=1024*np.ones(shape=(batch_size,1))
            #data=np.concatenate( (h, prior_data),axis=1)
            #L=-model.VQVAE.prior.compute_maxlikelihood(data)
            #opt2.zero_grad()
            #L.backward()
            #opt2.step()
            
            
        with torch.no_grad():
            data=val_data[:12]
            data=2.0*(data-data.min())/(data.max()-data.min())-1.0
            Lvae,Ldis,Lgen,Lper,prior_data=model.compute_loss(data)
            recon_test.append(Lvae.item())
        torch.save(model.state_dict(),'q3a.pth')
    dis_loss=np.array(dis_loss)
    per_loss=np.array(per_loss)
    recon_train=np.array(recon_train)
    recon_test=np.array(recon_test)
    data=reconstruct_data
    data=2.0*(data-data.min())/(data.max()-data.min())-1.0
    recon=model.VQVAE.recon(data).transpose(0,2,3,1)
    recon=(recon+1.0)/2.0
    
    return dis_loss,per_loss,recon_train,recon_test,recon

q3_save_results(q3a, "a")
