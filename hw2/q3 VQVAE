import copy
from deepul.hw2_helper import *
import numpy as np
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from transformer import ABS_RoPE,Embedding,Transformer_Block
device='cuda'

def _get_clones(module, N):
    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])


class iGPT(nn.Module):
    def __init__(self,d_model,vocab_size, H,W,context_length,num_layers,num_heads,d_ff,theta,max_seq_len):
        super().__init__()
        
        self.H=H
        self.W=W
        
        if max_seq_len==None:
            max_seq_len=context_length

        self.pe=ABS_RoPE(theta, d_model, max_seq_len).to(device)
        self.embedding=Embedding(vocab_size, d_model).to(device)
        
        Layer=Transformer_Block(d_model, num_heads, d_ff).to(device)
        
        self.Trans=_get_clones(Layer,num_layers)

        self.Linear=torch.nn.Linear(d_model, vocab_size-1)
        
        self.lm=torch.nn.LayerNorm(vocab_size-1).to(device)
        self.layers=num_layers
        self.d_model=d_model
        
        self.vocab_size=vocab_size
        
        self.softmax=torch.nn.Softmax(dim=-1)
    
    
    def forward(self,x:np.ndarray):
        
        x=torch.LongTensor(x).to(device)
        x=x.to(device)
        x=self.embedding(x)
        x=self.pe(x)
        for i in range(0,self.layers):
            x=self.Trans[i](x)
    
        x=self.Linear(x)
        x=self.lm(x)
        x=self.softmax(x)
        
        return x
    
    def compute_maxlikelihood(self,x:np.ndarray):
        prob=self.forward(x[:,:-1]).to(device)
        
        y=torch.LongTensor(x[:,1:]).to(dtype=torch.int64).to(device)
        y=y.unsqueeze(-1)
        p=torch.gather(prob, dim=-1, index=y).squeeze()
        L=torch.log(p)
        return L.mean()
    
    def sample(self,num_samples):
        with torch.no_grad():
            h=(self.vocab_size-1)*np.ones(shape=(num_samples,1))
            
            for i in range(0,self.H):
                for j in range(0,self.W):
                    probs=self.forward(h)
                    
                    dist=torch.distributions.Categorical(probs=probs)
                    next_pixcel=dist.sample().cpu().detach().numpy()[:,[-1]]
                    h=np.concatenate((h, next_pixcel),axis=1)
                    
            sample=h[:,1:]
            
            sample=sample.reshape((num_samples,self.H,self.W))
        return sample
        

class residual_block(nn.Module):
    def __init__(self,dim:int):
        super().__init__()
        self.bn1=torch.nn.BatchNorm2d(dim)
        self.acti=torch.nn.ReLU()
        self.conv1=torch.nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3,stride=1,padding=1)
        self.bn2=torch.nn.BatchNorm2d(dim)
        self.conv2=torch.nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3,stride=1,padding=1)
        
    def forward(self,x:torch.Tensor):
        x=self.bn1(x)
        x=self.acti(x)
        x=self.conv1(x)
        x=self.bn2(x)
        x=self.acti(x)
        x=self.conv2(x)
        return x
    
class Encoder(nn.Module):
    def __init__(self,dim:int):
        super().__init__()
        self.conv1=torch.nn.Conv2d(in_channels=3, out_channels=dim, kernel_size=4,stride=2,padding=1)
        self.bn1=torch.nn.BatchNorm2d(dim)
        self.acti=torch.nn.ReLU()
        self.conv2=torch.nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=4,stride=2,padding=1)
        self.rs1=residual_block(dim)
        self.rs2=residual_block(dim)
        
    def forward(self,x:torch.Tensor):
        x=self.conv1(x)
        x=self.bn1(x)
        x=self.acti(x)
        x=self.conv2(x)
        x=self.rs1(x)
        x=self.rs2(x)
        return x
    
class Decoder(nn.Module):
    def __init__(self,dim:int):
        super().__init__()
        self.rs1=residual_block(dim)
        self.rs2=residual_block(dim)
        self.bn1=torch.nn.BatchNorm2d(dim)
        self.acti=torch.nn.ReLU()
        self.conv1=torch.nn.ConvTranspose2d(in_channels=dim, out_channels=dim, kernel_size=4,stride=2,padding=1)
        self.bn2=torch.nn.BatchNorm2d(dim)
        self.conv2=torch.nn.ConvTranspose2d(in_channels=dim, out_channels=3, kernel_size=4,stride=2,padding=1)

    def forward(self,x:torch.Tensor):
        x=self.rs1(x)
        x=self.rs2(x)
        x=self.bn1(x)
        x=self.acti(x)
        x=self.conv1(x)
        x=self.bn2(x)
        x=self.acti(x)
        x=self.conv2(x)
        return x
    
class VQVAE(nn.Module):
    def __init__(self,dim:int,H,W,K,D,beta=0.2,gamma=0.99):
        super().__init__()
        self.dim=dim
        self.H=H
        self.W=W
        self.K=K
        self.D=D
        t=torch.empty((K,D),device=device)
        self.codebook=torch.nn.init.uniform_(t,-1,1)
        self.encoder=Encoder(self.dim).to(device)
        self.decoder=Decoder(self.dim).to(device)
        
        self.recon_fn=torch.nn.MSELoss()
        self.beta=beta
        self.gamma=0.99
        self.N=torch.zeros((K,),device=device)
        self.m=torch.zeros((128,256),device=device)
        self.prior=iGPT(d_model=128, vocab_size=K+1, H=self.H, W=self.W, 
                        context_length=self.H*self.W, num_layers=4, num_heads=4, d_ff=128, theta=10000, max_seq_len=self.H*self.W)
    def compute_ek(self,x:np.ndarray):
        x=torch.Tensor(x).to(device)
        Ex=self.encoder(x)
        batch_size=x.shape[0]
        Ex=Ex.reshape((batch_size,self.dim,self.H*self.W)).permute(0,2,1)  #(batch_size,64,256)
        Ex=Ex.reshape((batch_size*64,self.dim))
        
        dist=torch.cdist(Ex,self.codebook)
        indices=torch.argmin(dist,dim=-1)   #抽出和每个z最近的索引
        
        
        return Ex,indices
        
    def VAE_LOSS(self,x:np.ndarray):
        batch_size=x.shape[0]
        Ze,indices=self.compute_ek(x)
        indices=indices.unsqueeze(1)
        prior_data=indices.reshape((batch_size,64)).cpu().detach().numpy()
        ind2=indices
        indices=indices.broadcast_to((indices.shape[0],256)).to(torch.int64)
        Zq=torch.gather(self.codebook,dim=0,index=indices)
        
        feature=(Zq-Ze).detach()+Ze
        feature=feature.reshape((batch_size,64,256))
        feature=feature.permute(0,2,1)
        feature=feature.reshape((batch_size,256,self.H,self.W))
        
        Dx=self.decoder(feature)
        x=torch.Tensor(x).to(device)
        recon_loss=self.recon_fn(Dx,x)
        
        Ze=Ze.reshape((batch_size,64,256))
        ek=Zq.reshape((batch_size,64,256))
        sgZe=Ze.detach()
        VQ=self.recon_fn(sgZe,ek)
        
        sgek=ek.detach()
        comm_loss=self.recon_fn(Ze,sgek)
        
        
        #然后更新e_k
        with torch.no_grad():
            ind=torch.zeros((indices.shape[0],self.codebook.shape[0]),device=device)
            ind=ind.scatter(1, ind2, 1)
            
            self.N=self.gamma*self.N+(1-self.gamma)*ind.sum(dim=0)
            self.m=self.gamma*self.m+(1-self.gamma)*torch.matmul(ind.T,Ze.reshape((batch_size*64,256)))
            deno=self.N.sum()
            self.N=(self.N+1e-5)*deno/(deno+self.K*1e-5)
            self.codebook=self.m/self.N.unsqueeze(1)
        return recon_loss+VQ+self.beta*comm_loss,prior_data
    
    def recon(self,x:np.ndarray):
        with torch.no_grad():
            batch_size=x.shape[0]
            Ze,indices=self.compute_ek(x)
            x=torch.Tensor(x).to(device)
            
            indices=indices.unsqueeze(1)
            indices=indices.broadcast_to((indices.shape[0],256)).to(torch.int64)
            Zq=torch.gather(self.codebook,dim=0,index=indices)
            
            feature=Zq
            feature=feature.reshape((batch_size,64,256))
            feature=feature.permute(0,2,1)
            feature=feature.reshape((batch_size,256,self.H,self.W))
            
            Dx=self.decoder(feature)
        return Dx.cpu().detach().numpy()
    
    def sample(self,num_samples):
        sample=self.prior.sample(num_samples)  #采样出(100,8,8)个token
        sample=sample.reshape((6400,1))
        sample=torch.LongTensor(sample).to(device)
        sample=sample.broadcast_to((6400,self.D))
        zq=torch.gather(self.codebook,dim=0,index=sample)
        zq=zq.reshape((100,64,256)).permute((0,2,1))
        zq=zq.reshape((100,256,8,8))
        x=(self.decoder(zq)+1.0)*255.0/2.0
        return x.cpu().detach().numpy()
        
        


def q3(train_data, test_data, dset_id):
    test_data=test_data[:200].transpose((0,3,1,2))
    channel=train_data.shape[3]
    H=train_data.shape[1]
    W=train_data.shape[2]
    total=train_data.shape[0]
    batch_size=128
    n_batches=total//batch_size
    
    model=VQVAE(dim=256,H=8,W=8,K=128,D=256,beta=0.25)
    model.to(device)
    
    model.load_state_dict(torch.load('q3_2.pth'))
    epoch=0
    opt=torch.optim.Adam(model.parameters(),lr=2e-3)
    
    train_loss=[1]
    test_loss=[1]
    
    train_prior_loss=[1]
    test_prior_loss=[1]
    for i in range(0,epoch):
        rand_indices = np.random.randint(0,total, size=(batch_size*n_batches,))
        for j in range(0,n_batches):
            data=train_data[rand_indices[j*batch_size:(j+1)*batch_size]]
            data=data.transpose((0,3,1,2))   #卷积的输入要求(batch_size, channel, H,W)
            data=2.0*(data-data.min())/(data.max()-data.min())-1.0
            L,prior_data=model.VAE_LOSS(data)
            
            train_loss.append(L.item())
            print(i,L.item())
            opt.zero_grad()
            L.backward()
            opt.step()
            
            h=128*np.ones(shape=(batch_size,1))
            data=np.concatenate( (h, prior_data),axis=1)
            L=-model.prior.compute_maxlikelihood(data)
            opt.zero_grad()
            L.backward()
            opt.step()
            train_prior_loss.append(L.item())
        with torch.no_grad():
            L,_=model.VAE_LOSS(2.0*test_data/255.0-1.0)
            test_loss.append(L.item())
    torch.save(model.state_dict(),'q3_2.pth')
    
    rand1=np.random.randint(0,total,size=(50,))
    tar=train_data[rand1].transpose(0,3,1,2)
    tar=2.0*(tar-tar.min())/(tar.max()-tar.min())-1.0
    reconstruction=model.recon(tar).transpose(0,2,3,1)
    tar=tar.transpose(0,2,3,1)
    reconstruction=reconstruction[:,np.newaxis,:,:,:]
    tar=tar[:,np.newaxis,:,:,:]
    print(reconstruction)
    rec=np.concatenate( (tar, reconstruction),axis=1)
    rec=(rec.reshape((-1,32,32,3))+1)*255/2
    
    sample=model.sample(100).transpose(0,2,3,1)
    return train_loss,test_loss,train_prior_loss ,test_loss,sample,rec
q3_save_results(2, q3)


