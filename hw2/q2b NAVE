from deepul.hw2_helper import *
import numpy as np
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
device='cuda'

class Encoder(nn.Module):
    def __init__(self,latent_dim):
        super().__init__()
        self.latent_dim=latent_dim
        
        self.conv1=nn.Conv2d(in_channels=3+12, out_channels=32, kernel_size=3,padding=1)
        self.L1=torch.nn.LayerNorm(32)
        
        self.acti=nn.ReLU()
        self.conv2=nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3,stride=2,padding=1)
        self.L2=torch.nn.LayerNorm(64)
        self.conv3=nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,stride=2,padding=1)
        self.L3=torch.nn.LayerNorm(64)
        self.conv4=nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,stride=2,padding=1)
        self.L4=torch.nn.LayerNorm(64)
        self.conv5=nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,stride=2,padding=1)
        self.L5=torch.nn.LayerNorm(64)
        self.conv6=nn.Conv2d(in_channels=64, out_channels=12*2, kernel_size=3,padding=1)
        
    def forward(self,x:torch.Tensor):
        x=self.conv1(x)
        x=self.L1(x.permute(0,2,3,1)).permute(0,3,1,2)
        x=self.acti(x)
        x=self.conv2(x)
        x=self.L2(x.permute(0,2,3,1)).permute(0,3,1,2)
        x=self.acti(x)
        x=self.conv3(x)
        x=self.L3(x.permute(0,2,3,1)).permute(0,3,1,2)
        x=self.acti(x)
        x=self.conv4(x)
        x=self.L4(x.permute(0,2,3,1)).permute(0,3,1,2)
        x=self.acti(x)
        x=self.conv5(x)
        x=self.L5(x.permute(0,2,3,1)).permute(0,3,1,2)
        x=self.acti(x)
        x=self.conv6(x)
        return x
class Encoder2(nn.Module):
    def __init__(self,latent_dim):
        super().__init__()
        self.latent_dim=latent_dim
        
        self.conv1=nn.Conv2d(in_channels=12, out_channels=32, kernel_size=3,padding=1)
        self.L1=torch.nn.LayerNorm(32)
        
        self.acti=nn.ReLU()
        self.conv2=nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3,stride=2,padding=1)
        self.L2=torch.nn.LayerNorm(64)
        self.conv3=nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,stride=2,padding=1)
        self.L3=torch.nn.LayerNorm(64)
        self.conv4=nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,stride=2,padding=1)
        self.L4=torch.nn.LayerNorm(64)
        self.conv5=nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,stride=2,padding=1)
        self.L5=torch.nn.LayerNorm(64)
        self.conv6=nn.Conv2d(in_channels=64, out_channels=12, kernel_size=3,padding=1)
        
    def forward(self,x:torch.Tensor):
        x=self.conv1(x)
        x=self.L1(x.permute(0,2,3,1)).permute(0,3,1,2)
        x=self.acti(x)
        x=self.conv2(x)
        x=self.L2(x.permute(0,2,3,1)).permute(0,3,1,2)
        x=self.acti(x)
        x=self.conv3(x)
        x=self.L3(x.permute(0,2,3,1)).permute(0,3,1,2)
        x=self.acti(x)
        x=self.conv4(x)
        x=self.L4(x.permute(0,2,3,1)).permute(0,3,1,2)
        x=self.acti(x)
        x=self.conv5(x)
        x=self.L5(x.permute(0,2,3,1)).permute(0,3,1,2)
        x=self.acti(x)
        x=self.conv6(x)
        return x
class Decoder(nn.Module):
    def __init__(self,latent_dim):
        super().__init__()
        self.latent_dim=latent_dim
        
        self.acti=nn.ReLU()
        
        self.conv1=nn.ConvTranspose2d(12, out_channels=64, kernel_size=3,padding=1)
        
        self.conv2=nn.ConvTranspose2d(64, out_channels=64, kernel_size=4,stride=2,padding=1)
        self.conv3=nn.ConvTranspose2d(64,  out_channels=64, kernel_size=4,stride=2,padding=1)
        self.conv4=nn.ConvTranspose2d(64,  out_channels=64, kernel_size=4,stride=2,padding=1)
        self.conv5=nn.ConvTranspose2d(64,  out_channels=32, kernel_size=4,stride=2,padding=1)
        self.conv6=nn.Conv2d(in_channels=32, out_channels=3, kernel_size=3,padding=1)
    
    def forward(self,x:torch.Tensor):
        x=self.conv1(x)
        x=self.acti(x)
        x=self.conv2(x)
        x=self.acti(x)
        x=self.conv3(x)
        x=self.acti(x)
        x=self.conv4(x)
        x=self.acti(x)
        x=self.conv5(x)
        x=self.acti(x)
        x=self.conv6(x)
        
        return x
    
class NVAE(nn.Module):
    def __init__(self,latent_dim):
        super().__init__()
        self.latent_dim=latent_dim
        self.q_z1_given_x=Encoder(self.latent_dim)
        
        self.p_z1=torch.distributions.MultivariateNormal(loc=torch.zeros((48,),device=device),
                                                         covariance_matrix=torch.eye(48,device=device)*1.0)
        self.p_z2_given_z1=Encoder2(self.latent_dim)
        
        self.q_z2=Encoder(self.latent_dim)
        
        self.decoder=Decoder(self.latent_dim)
        
        self.recon_fn=torch.nn.MSELoss()
        
    
    def Recon_loss(self,x:np.ndarray):
        x=torch.Tensor(x).to(device)
        batch_size=x.shape[0]
        z1=torch.zeros((batch_size,12,32,32),device=device)
        
        #采样z1
        feature=torch.concat([z1,x],dim=1)
        mean,logstd=self.q_z1_given_x(feature).split(self.latent_dim,dim=1)
        mean=mean.reshape((batch_size,48))
        logstd=logstd.reshape((batch_size,48))
        dis_z1=torch.distributions.MultivariateNormal(loc=mean,covariance_matrix=torch.diag_embed(torch.exp(2.0*logstd)))
        
        cov=torch.exp(2.0*logstd)
        KL1=0.5*(cov-2.0*logstd+mean**2-1).sum(dim=-1).mean()
        
        z1=dis_z1.rsample()
        z1=z1.reshape((batch_size,12,2,2))
        z1=F.interpolate(z1,size=(32,32),mode='nearest')   #上采样到(12,32,32)
        
        features=torch.concat([z1,x],dim=1)
        mean_z2,logstd_z2=self.q_z2(feature).split(self.latent_dim,dim=1)
        mean_z2=mean_z2.reshape((batch_size,48))
        logstd_z2=logstd_z2.reshape((batch_size,48))
        out=-logstd_z2-0.5+(torch.exp(2*logstd_z2)+mean_z2**2)*0.5
        KL2=out.sum(dim=-1).mean()
        
        mean=self.p_z2_given_z1(z1)
        mean=mean.reshape((batch_size,48))
        
        q_z2=torch.distributions.MultivariateNormal(loc=mean+mean_z2,covariance_matrix=torch.diag_embed(torch.exp(2*logstd_z2)))
        z2=q_z2.rsample().reshape((batch_size,12,2,2))
        y=self.decoder(z2)
        
        recon_loss=0.5*self.recon_fn(y,x)
        
        return recon_loss+KL1+KL2,recon_loss,KL1+KL2
    
    def sample(self,num_sample):
        with torch.no_grad():
            batch_size=num_sample
            z1=self.p_z1.sample((batch_size,))
            
            #采样z1
            
            z1=z1.reshape((batch_size,12,2,2))
            z1=F.interpolate(z1,size=(32,32),mode='nearest')   #上采样到(12,32,32)
            
            mean=self.p_z2_given_z1(z1)
            mean=mean.reshape((batch_size,48))
            
            q_z2=torch.distributions.MultivariateNormal(loc=mean,
                                                covariance_matrix=torch.diag_embed(torch.ones((batch_size,48),device=device)))
            z2=q_z2.sample().reshape((batch_size,12,2,2))
            y=self.decoder(z2)
        return y.cpu().detach().numpy()
    

def q2_b(train_data, test_data, dset_id):
    
    test_data=test_data[:200].transpose((0,3,1,2))
    channel=train_data.shape[3]
    H=train_data.shape[1]
    W=train_data.shape[2]
    total=train_data.shape[0]
    batch_size=128
    n_batches=total//batch_size
    
    model=NVAE(latent_dim=12)
    model.to(device)
    
    model.load_state_dict(torch.load('q2_b_svhn.pth'))
    
    epoch=0
    opt=torch.optim.Adam(model.parameters(),lr=1e-3)
    
    train_loss=[]
    test_loss=[]
    for i in range(0,epoch):
        rand_indices = np.random.randint(0,total, size=(batch_size*n_batches,))
        for j in range(0,n_batches):
            data=train_data[rand_indices[j*batch_size:(j+1)*batch_size]]
            data=data.transpose((0,3,1,2))   #卷积的输入要求(batch_size, channel, H,W)
            
            ELBO,rec,KL=model.Recon_loss(data)
            print(i,ELBO.item())
            opt.zero_grad()
            ELBO.backward()
            opt.step()
            
            train_loss.append([ELBO.item(),rec.item(),KL.item()])
        with torch.no_grad():
            ELBO,rec,KL=model.Recon_loss(test_data)
            test_loss.append([ELBO.item(),rec.item(),KL.item()])
            
    torch.save(model.state_dict(),'q2_b_svhn.pth')
    
    train_loss=np.array(train_loss)
    test_loss=np.array(test_loss)
    
    sample=model.sample(100).transpose(0,2,3,1)
    
    return train_loss,test_loss,sample,sample,sample

q2_save_results('b', 1, q2_b)
